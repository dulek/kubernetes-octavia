<!DOCTYPE html>
<html>
  <head>
    <title>
        Kubernetes and Octavia - a love-hate relationship
    </title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <link rel="stylesheet" href="slides.css"></link>
  </head>
  <body>
    <textarea id="source">

layout: true
name: title_layout
class: title_slide

---

layout: true
name: section_layout
class: section_slide

---

layout: true
name: agenda_layout
class: content_slide agenda_slide

---

layout: true
name: thank_you
class: thank_you

---

layout: true
name: content_layout
class: content_slide

---

template: title_layout

# Kubernetes and Octavia

## a love-hate relationship

Michał Dulko - Senior Software Engineer<br />
<br>
OpenInfra Summit Vancouver, 14.07.2023<br />

Slides available at: **https://dulek.github.io/kubernetes-octavia**

???

* We've spent time validating cloud-provider-openstack with Octavia.
* This presentation shares our experiences.

---

template: section_layout

What I'll talk about?

???

* Only about `type=LoadBalancer` Services.
* MetalLB

---

template: section_layout

What I won't talk about?

???

* No octavia-ingress-controller even though it's a part of cloud-provider-openstack.
* No CAPO API LB integration.
* All because I don't have as much experience.

---

template: section_layout

<span style="font-weight: normal">**in-tree** vs **out-of-tree**</span>

???

* Split a while ago.
* Easy to use in-tree, you might be tempted.

---

# cloud-provider-openstack

## in-tree vs out-of-tree

* in-tree is **removed** in Kubernetes **1.26**
--

* in-tree Octavia support was implemented like this:

```go
	if os.lbOpts.UseOctavia {
		lb, err = openstack.NewLoadBalancerV2(os.provider, gophercloud.EndpointOpts{
			Region: os.region,
		})
	} else {
		lb, err = openstack.NewNetworkV2(os.provider, gophercloud.EndpointOpts{
			Region: os.region,
		})
	}
```
--
* Possible as **Neutron LBaaS v2 API = Octavia v2.0 API**
--

* Missing features:
  * **Fully populated LB creation**
  * **Health monitors support**
  * Cascade delete
  * Configurable timeouts

---
# Octavia
## Backends a.k.a. providers

.left-column[

### Amphora Provider
* Reference implementation
* Each LB is a VM with HAProxy
* Slow to create or update
* No source IP preservation
  * HTTP header or PROXY protocol can be used
]

???
* Octavia is not a perfect abstraction layer
* "Providers" confusion

--
.right-column[
### OVN Octavia Provider
* *Secondary* implementation
* LBs implemented using underlying Neutron OVN instance
* Fast to configure
* Source IP preservation by default
* Functional gaps

```ini
[LoadBalancer]
lb-provider = ovn
lb-method = SOURCE_IP_PORT
```
]

???
* There are more backends out there, like F5 provider.

---

# LoadBalancer Services
## Load balancer setup

.left-column[![LB1](excalidraw/lb1.png)]
--

.right-column[
* Each node is a member of the LB.
  * Regardless of if it has a Service pod.
* What about scale?
  * ** `ACTIVE`-`PENDING_UPDATE` dance is not acceptable. Fully populated
creation is a must!**
]

---

# LoadBalancer Services
## Simple case

.left-column[![LB2](excalidraw/lb2.png)]

---

# LoadBalancer Services
## Redirection, externalTrafficPolicy=Cluster (default)

.left-column[![LB2](excalidraw/lb3.png)]

.right-column[
* `externalTrafficPolicy=Cluster`
  * Better traffic spread
  * May cause another hop
  * Source IP is lost
]

---

# LoadBalancer Services
## externalTrafficPolicy=Local

.left-column[![LB2](excalidraw/lb4.png)]
--

.right-column[
* `externalTrafficPolicy=Local`
  * Source IP preservation
  * No additional hops
  * Worse traffic spread
]

---

# LoadBalancer Services
## externalTrafficPolicy=Local

.left-column[![LB2](excalidraw/lb5.png)]

---

# LoadBalancer Services
## externalTrafficPolicy=Local

.left-column[![LB2](excalidraw/lb6.png)]
--

.right-column[
* Amphora **does not** preserve source IP by default
  * `loadbalancer.openstack.org/x-forwarded-for` annotation for HTTP
  * `loadbalancer.openstack.org/proxy-protocol` to use PROXY protocol
* OVN-Octavia does, but:
  * It only supports health monitors starting from Wallaby
]

---

# Octavia API versions

<table border="1">
<thead>
<tr class="row-odd"><th class="head">OpenStack version</th>
<th class="head">Max Octavia API version</th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td>Train</td>
<td>v2.13</td>
</tr>
<tr class="row-odd"><td>Ussuri</td>
<td>v2.16</td>
</tr>
<tr class="row-even"><td>Victoria</td>
<td>v2.23</td>
</tr>
<tr class="row-odd"><td>Wallaby</td>
<td>v2.24</td>
</tr>
<tr class="row-even"><td>Xena</td>
<td>v2.24</td>
</tr>
<tr class="row-odd"><td>Zed</td>
<td>v2.25</td>
</tr>
<tr class="row-even"><td>Antelope</td>
<td>v2.26</td>
</tr>
</tbody>
</table>

Source: https://opendev.org/openstack/octavia/src/branch/master/octavia/api/root_controller.py

---

# Octavia healthmonitors
## Compatiblity in different versions

* OVN only supports healthmonitors starting from Wallaby.
  * **Do not check Octavia API version!**
--

* Endpoint on `healthCheckNodePort` is HTTP.
  * Amphora does not support HTTP monitors on UDP pools until v2.16 (Ussuri).
--

  * OVN does not support HTTP monitors at all.
--

  * cloud-provider-openstack will fallback to TCP/UDP-CONNECT monitors **on
    NodePorts**.
       * Consequence: UDP-CONNECT monitor needs connection to be REJECT
	     and not DROP. 
       * Proper CNI will do DROP.
--
* Members are ON by default.

---

# Other LoadBalancer options
## `sessionAffinity`
--

* Implemented using `session_persistence` on pool set to `SOURCE_IP`.
--

  * **Only works with Amphora!**
--

  * But it's implementable in OVN too!
--

      * *COMING SOON!*

--

## `loadBalancerSourceRanges`
--

* Implemented using `allowed_cidrs` on listeners.
	* Supported since v2.12 (Train).
--

	* **Only works with Amphora!**
--

* On OVN you need to manage this on members SG:
  * `manage-security-groups` option of cloud-provider-openstack **will do** that.

---

# manage-security-groups
## cloud-provider-openstack option

.left-column[![LB](excalidraw/lb7.png)]
--

.right-column[
* No SG management:
  * Open NodePort range on each (30000-32767)
      * Amphora: Nodes subnet
      * OVN: **0.0.0.0/0**
]

---

# manage-security-groups
## cloud-provider-openstack option

.left-column[![LB](excalidraw/lb7.png)]

.right-column[
* No SG management:
  * Open NodePort range on each (30000-32767)
      * Amphora: Nodes subnet
      * OVN: **0.0.0.0/0**
* `manage-security-groups`:
  * cloud-provider-openstack:
      * Creates SG per LB Service.
      * Opens only required port**s**.
      * Assigns it to nodes.
]

---

# manage-security-groups
## cloud-provider-openstack option

.left-column[![LB](excalidraw/lb7.png)]

.right-column[
* `manage-security-groups` with **OVN WiP**:
  * Currently broken with OVN as it opens Nodes range.
  * Option to implement `loadBalancerSourceRanges`.
]

---

# MetalLB
## A viable alternative?

https://that.guru/blog/deploying-metallb-on-openstack-part-1/

https://that.guru/blog/deploying-metallb-on-openstack-part-2/

???

Had anyone tried MetalLB?

--

.left-column[</br>![MetalLB](assets/metallb.png)]

--

.right-column[
* MetalLB spoofs source IP address
* allowed-address-pairs will block this
* Options:
    * Disable port security
    * Configure allowed-address-pairs dynamically
    * Use a secondary port firewalled differently
]

---

# Summary

* **Don't use in-tree cloud-provider-openstack.**
--

* Amphora:
    * High resource consumption.
    * Good K8s compatibility.
--
* OVN:
    * Fast, low resource consumption.
    * K8s compatibility is *we're getting there*:
        * Main issues around safe SG management.
        * UDP services.

--

* If using UDP Services - double-check everything.
--

* MetalLB:
    * Not a silver bullet yet.
    * Try if fed up with Octavia.

---

# cloud-provider-openstack

## How to use, how to contribute

### Kubernetes on OpenStack Forum Session on Thursday at 2 PM!

--

* Code: https://github.com/kubernetes/cloud-provider-openstack
* Documentation: https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs
* [#provider-openstack on K8s Slack](https://kubernetes.slack.com/archives/C0LSA3T7C)
* Bugs: https://github.com/kubernetes/cloud-provider-openstack/issues

---

template: section_layout

![CC](assets/cc.svg)
.medium-text[
Slides are available on

http://creativecommons.org/licenses/by/4.0/
]

---

template: thank_you

# Q&A

## Thank you!

**Slides can be found at:**

- https://dulek.github.io/kubernetes-octavia
- https://github.com/dulek/kubernetes-octavia

**Michał Dulko**

![email](assets/email.png)   [mdulko@redhat.com](mailto:mdulko@redhat.com)
![irc](assets/irc.png)   dulek (K8s Slack)

    </textarea>
    <script src="remark.js" type="text/javascript"></script>
    <script type="text/javascript">
      var slideshow = remark.create({
        ratio: '16:9',
        slideNumberFormat: '%current%   <span class="designator">Kubernetes and Octavia - a love-hate relationship · June 2023 · OpenInfra Summit Vancouver · <strong><a href="https://dulek.github.io/kubernetes-octavia">https://dulek.github.io/kubernetes-octavia</a></strong></span>',
        countIncrementalSlides: false
      });
    </script>
  </body>
</html>

<!-- vim: set ft=markdown : -->
